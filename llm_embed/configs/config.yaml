

dataset:
  prompt_path: 'data/prompt_parsed.json'
  label_path: 'data/label_dict.json'
  section: "2"
  start_row_num: 0 # 1000, 2000
  event_id: "BL" # "all" # ['BL', 'V02', 'V04', 'V06', 'V08']


model:
  model_name: "/nfs_inf/public/hf/models/meta-llama/Llama-3.2-1B" # Meta-Llama-3.1-8B" # Llama-3.2-1B" # Llama-3.2-3B-Instruct" # Local path to the model
  # cache_dir: 
  kwargs:
    return_dict_in_generate: True
    output_hidden_states: True
    do_sample: False

tokenizer:
  kwargs:
    # output_hidden_states: True
    return_tensors: "pt"
    padding: "max_length"
    truncation: True
    max_length: !!int 4024
    return_attention_mask: True
    return_token_type_ids: True
    return_overflowing_tokens: False
    return_special_tokens_mask: False
    return_offsets_mapping: False
    return_length: False
    is_split_into_words: False
    verbose: False

exp:
  batch_size: 2